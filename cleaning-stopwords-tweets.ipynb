{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 most frequent words:\n",
      "         word  count\n",
      "612     women    148\n",
      "92   families    147\n",
      "425      jobs    112\n",
      "187       job    112\n",
      "402       tax     96\n",
      "417   economy     84\n",
      "560     fight     74\n",
      "959      wall     71\n",
      "364    united     67\n",
      "264     woman     66\n",
      "Word frequencies saved to 'word_frequencies_no_stopwords.csv'.\n",
      "Tokenized tweets without stopwords saved to 'tweets_no_stopwords.csv'.\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the cleaned tweets dataset\n",
    "tweets_df = pd.read_csv('tweets_cleaned.csv')\n",
    "\n",
    "# Load custom stopwords from the provided file\n",
    "with open('stopwords.txt', 'r') as file:\n",
    "    custom_stopwords = set(line.strip() for line in file if line.strip())\n",
    "\n",
    "# Function to remove stopwords from the cleaned text\n",
    "def remove_stopwords(text):\n",
    "    tokens = text.split()\n",
    "    tokens = [word for word in tokens if word not in custom_stopwords]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply stopwords removal to the cleaned_text column\n",
    "tweets_df['cleaned_text_no_stopwords'] = tweets_df['cleaned_text'].apply(remove_stopwords)\n",
    "\n",
    "# Flatten all words from the cleaned_text_no_stopwords into a single list for counting\n",
    "all_words = [word for text in tweets_df['cleaned_text_no_stopwords'] for word in text.split()]\n",
    "\n",
    "# Count the frequency of each word using Counter\n",
    "word_counts = Counter(all_words)\n",
    "\n",
    "# Convert word counts to a DataFrame for easy analysis\n",
    "word_counts_df = pd.DataFrame(word_counts.items(), columns=['word', 'count']).sort_values(by='count', ascending=False)\n",
    "\n",
    "# Display the top 10 most frequent words for verification\n",
    "print(\"Top 10 most frequent words:\")\n",
    "print(word_counts_df.head(10))\n",
    "\n",
    "# Save the word frequencies to a CSV file for Tableau visualization\n",
    "word_counts_df.to_csv('word_frequencies_no_stopwords.csv', index=False)\n",
    "print(\"Word frequencies saved to 'word_frequencies_no_stopwords.csv'.\")\n",
    "\n",
    "# Save the tokenized tweets (without stopwords) for further analysis in Tableau\n",
    "tweets_df.to_csv('tweets_no_stopwords.csv', index=False)\n",
    "print(\"Tokenized tweets without stopwords saved to 'tweets_no_stopwords.csv'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
